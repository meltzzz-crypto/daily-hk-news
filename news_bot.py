import feedparser
import requests
import os
import time
from datetime import datetime
from bs4 import BeautifulSoup

# ì„¤ì •
RSS_URL = "https://www.mk.co.kr/rss/50300009/"
WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")

def get_summary_from_url(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, "html.parser")
        
        # ë³¸ë¬¸ ì°¾ê¸° (ë§¤ì¼ê²½ì œ ì‚¬ì´íŠ¸ êµ¬ì¡° ë¶„ì„)
        content = ""
        for selector in ["div.art_txt", "div.news_cnt_detail_wrap", ".txt_area"]:
            element = soup.select_one(selector)
            if element:
                content = element.get_text(separator=" ").strip()
                break
        
        if not content: return None

        # 3ë¬¸ì¥ ìš”ì•½ (ê°„ë‹¨í•œ ë¡œì§)
        sentences = content.split('ë‹¤.')
        summary = []
        for s in sentences:
            s = s.strip()
            if len(s) > 30 and "ê¸°ì" not in s: # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸°ì ì´ë¦„ ë“± ì œì™¸
                summary.append(s + 'ë‹¤.')
                if len(summary) >= 3: break
        
        return summary
    except:
        return None

def fetch_rss_news():
    print("ë‰´ìŠ¤ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    feed = feedparser.parse(RSS_URL)
    news_items = []
    
    # 13ê°œ ê°€ì ¸ì˜¤ê¸°
    for entry in feed.entries[:13]:
        link = entry.link
        print(f"ì²˜ë¦¬ ì¤‘: {entry.title}")
        
        # ë³¸ë¬¸ ìš”ì•½ ì‹œë„
        summary_points = get_summary_from_url(link)
        
        if summary_points:
            desc = "\n".join([f"- {p}" for p in summary_points])
        else:
            desc = entry.description[:100] + "..." # ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ìš”ì•½
            
        news_items.append({
            "title": entry.title,
            "link": link,
            "summary": desc,
            "published": entry.published
        })
        time.sleep(0.5)
    
    return news_items

def send_to_discord(items):
    if not items: return
    
    # 10ê°œì”© ë‚˜ëˆ ì„œ ë³´ë‚´ê¸° (ë””ìŠ¤ì½”ë“œ ì œí•œ)
    chunks = [items[i:i + 10] for i in range(0, len(items), 10)]
    
    for i, chunk in enumerate(chunks):
        embeds = []
        if i == 0:
            embeds.append({
                "title": "ğŸ“° ë§¤ì¼ê²½ì œ ë¶€ë™ì‚° ì£¼ìš” ë‰´ìŠ¤ (13ì„ )",
                "description": f"{datetime.now().strftime('%Y-%m-%d')} ì•„ì¹¨ ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤.",
                "color": 0x00ff00
            })
            
        for item in chunk:
            embeds.append({
                "title": item['title'],
                "url": item['link'],
                "description": item['summary'],
                "footer": {"text": "MK News"}
            })
            
        requests.post(WEBHOOK_URL, json={"username": "MKë¶€ë™ì‚°ë‰´ìŠ¤ë´‡", "embeds": embeds})
        time.sleep(1)

if __name__ == "__main__":
    news = fetch_rss_news()
    send_to_discord(news)
